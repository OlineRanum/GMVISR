pretrained: new_models/NGT200/kfold_animics/1_2_3/T1/epoch=231-step=10440.ckpt
data:
    variables:
        MODEL_NAME: &model_name 1_2_3_test_1
        PROJECT_NAME: &project_name NGT200

        # Set Data paths
        OUTPUT_PATH: &output_path new_models/NGT200/1_2_3/T1/f/
        DATA_PATH: &data_path training_data/NGT/metadata/kfold/test/T1_f.json
        POSE_PATH: &pose_path training_data/NGT/Poses/
        TARGET_PATH: &target_path  openhands.datasets.isolated.WLASLDataset

        RESULT_PATH: &result_path results/NGT200/kfold_animics/1_2_3/T1/f/_1.jsonl
        
        # Set modality
        MOD: &modality "pose"

        # Select phonological parameters
        PARAMETERS: &params  [
                #"Handshape"
                # "Selected Fingers"
                # "Flexion",
                # "Spread",
                # "Spread Change",
                # "Thumb Position",
                # "Thumb Contact",
                # "Sign Type",
                # "Path Movement",
                # "Repeated Movement",
                # "Major Location",
                # "Minor Location"
                # "Second Minor Location",
                # "Contact",
                # "Nondominant Handshape", 
                # "Wrist Twist",
                # "Handshape Morpheme 2"
            ]

    modality: *modality
    
    test_pipeline:
            dataset:
                _target_: *target_path
                split_file: *data_path
                root_dir: *pose_path
                splits: "test"
                modality: *modality
                inference_mode: true
            results: *result_path


            transforms:
                - PoseSelect:
                    preset: mediapipe_holistic_minimal_27
                - CenterAndScaleNormalize:
                    reference_points_preset: shoulder_mediapipe_holistic_minimal_27
                    scale_factor: 1

            dataloader:
                _target_: torch.utils.data.DataLoader
                batch_size: 32
                shuffle: false
                num_workers: 3
                pin_memory: true
                drop_last: false
            
            parameters: *params

model:
    encoder:
        type: decoupled-gcn
        params:
            # pretrained adapters to fuse (only makes sense when learn_adapter is true)
            adapters: []
            # learns an adapter for the selected CLF heads. if there isn't a `pretrained` option on line 1, it'll learn all params (model+adpter)
            learn_adapter: false
            graph_args:
                num_nodes: 27
                inward_edges:
                    [
                        [2, 0],
                        [1, 0],
                        [0, 3],
                        [0, 4],
                        [3, 5],
                        [4, 6],
                        [5, 7],
                        [6, 17],
                        [7, 8],
                        [7, 9],
                        [9, 10],
                        [7, 11],
                        [11, 12],
                        [7, 13],
                        [13, 14],
                        [7, 15],
                        [15, 16],
                        [17, 18],
                        [17, 19],
                        [19, 20],
                        [17, 21],
                        [21, 22],
                        [17, 23],
                        [23, 24],
                        [17, 25],
                        [25, 26],
                    ]
    decoder:
        type: param_fc
        params:
            dropout_ratio: 0
        parameters: *params


optim:
    loss: 'CrossEntropyLoss'
    optimizer:
        name: Adam
        params:
            lr: 1e-3

    scheduler:
        name: CosineAnnealingLR
        params:
            last_epoch: -1
            T_max: 10

trainer:
    max_epochs: 1000

exp_manager:
    create_tensorboard_logger: true
    create_wandb_logger: true
    wandb_logger_kwargs:
        name: *model_name
        project: *project_name

    create_checkpoint_callback: true
    checkpoint_callback_params:
        monitor: "val_acc"
        mode: "max"
        save_top_k: 3
        dirpath: *output_path

    early_stopping_callback: true
    early_stopping_params:
        monitor: "val_acc"
        patience: 80
        verbose: true
        mode: "max"
